<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="utf-8">
  
  <title>web推荐系统知识介绍 | 张先森的代码小屋</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  
  <meta name="keywords" content="统计分析">
  
  
  
  
  <meta name="description" content="利用数据提供某种建议是很常见的需求，它可以改善用户体验，好的推荐系统可以比较精准地为用户提供信息，增加购买率。">
<meta name="keywords" content="统计分析">
<meta property="og:type" content="article">
<meta property="og:title" content="web推荐系统知识介绍">
<meta property="og:url" content="https://nullcc.github.io/2017/05/10/web推荐系统知识介绍/index.html">
<meta property="og:site_name" content="张先森的代码小屋">
<meta property="og:description" content="利用数据提供某种建议是很常见的需求，它可以改善用户体验，好的推荐系统可以比较精准地为用户提供信息，增加购买率。">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://nullcc.github.io/assets/images/post_imgs/recommend_system_1.png">
<meta property="og:image" content="https://nullcc.github.io/assets/images/post_imgs/recommend_system_2.png">
<meta property="og:image" content="http://images.cnitblog.com/blog2015/70278/201504/292243027244041.png">
<meta property="og:image" content="https://nullcc.github.io/assets/images/post_imgs/recommend_system_3.png">
<meta property="og:image" content="https://nullcc.github.io/assets/images/post_imgs/recommend_system_4.png">
<meta property="og:image" content="https://nullcc.github.io/assets/images/post_imgs/recommend_system_5.png">
<meta property="og:image" content="https://nullcc.github.io/assets/images/post_imgs/recommend_system_6.png">
<meta property="og:image" content="https://nullcc.github.io/assets/images/post_imgs/recommend_system_7.png">
<meta property="og:image" content="https://nullcc.github.io/assets/images/post_imgs/recommend_system_8.png">
<meta property="og:image" content="https://nullcc.github.io/assets/images/post_imgs/recommend_system_9.png">
<meta property="og:image" content="https://nullcc.github.io/assets/images/post_imgs/recommend_system_10.png">
<meta property="og:updated_time" content="2022-04-15T03:41:13.026Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="web推荐系统知识介绍">
<meta name="twitter:description" content="利用数据提供某种建议是很常见的需求，它可以改善用户体验，好的推荐系统可以比较精准地为用户提供信息，增加购买率。">
<meta name="twitter:image" content="https://nullcc.github.io/assets/images/post_imgs/recommend_system_1.png">
  
    <link rel="alternate" href="/atom.xml" title="张先森的代码小屋" type="application/atom+xml">
  
  <link rel="icon" href="/css/images/favicon.ico">
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link href="https://fonts.googleapis.com/css?family=Open+Sans|Montserrat:700" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Roboto:400,300,300italic,400italic" rel="stylesheet" type="text/css">
  <link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">
  <style type="text/css">
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/9749f0/00000000000000000001008f/27/l?subset_id=2&fvd=n5) format("woff2");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/90cf9f/000000000000000000010091/27/l?subset_id=2&fvd=n7) format("woff2");font-weight:500;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/8a5494/000000000000000000013365/27/l?subset_id=2&fvd=n4) format("woff2");font-weight:lighter;font-style:normal;}
    @font-face{font-family:futura-pt;src:url(https://use.typekit.net/af/d337d8/000000000000000000010095/27/l?subset_id=2&fvd=i4) format("woff2");font-weight:400;font-style:italic;}</style>
    
  <link rel="stylesheet" id="athemes-headings-fonts-css" href="//fonts.googleapis.com/css?family=Yanone+Kaffeesatz%3A200%2C300%2C400%2C700&amp;ver=4.6.1" type="text/css" media="all">

  <link rel="stylesheet" id="athemes-headings-fonts-css" href="//fonts.googleapis.com/css?family=Oswald%3A300%2C400%2C700&amp;ver=4.6.1" type="text/css" media="all">
  <link rel="stylesheet" href="/css/style.css">

  <script src="/js/jquery-3.1.1.min.js"></script>

  <!-- Bootstrap core CSS -->
  <link rel="stylesheet" href="/css/bootstrap.css">
  <link rel="stylesheet" href="/css/fashion.css">
  <link rel="stylesheet" href="/css/glyphs.css">

</head>
</html>


  <body data-spy="scroll" data-target="#toc" data-offset="50">


  


<header id="allheader" class="site-header" role="banner" 
   >
  <div class="clearfix container">
      <div class="site-branding">

          <h1 class="site-title">
            
              <a href="/" rel="home" >
                <img style="margin-bottom: 10px;"  width="124px" height="124px" alt="Hike News" src=" /css/images/logo.jpg">
              </a>
            
          </h1>
          
          
            <div class="site-description">明镜止水</div>
          
            
          <nav id="main-navigation" class="main-navigation" role="navigation">
            <a class="nav-open">Menu</a>
            <a class="nav-close">Close</a>

            <div class="clearfix sf-menu">
              <ul id="main-nav" class="menu sf-js-enabled sf-arrows"  style="touch-action: pan-y;">
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/">首页</a> </li>
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/archives">归档</a> </li>
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/categories">分类</a> </li>
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/tags">标签</a> </li>
                    
                      <li class="menu-item menu-item-type-custom menu-item-object-custom menu-item-home menu-item-1663"> <a class="" href="/about">关于</a> </li>
                    
              </ul>
            </div>
          </nav>

      </div>
  </div>
</header>


  <div id="container">
    <div id="wrap">
            
      <div id="content" class="outer">
        
          <section id="main" style="float:none;"><article id="post-web推荐系统知识介绍" style="width: 66%; float:left;" class="article article-type-post" itemscope itemprop="blogPost" >
  <div id="articleInner" class="clearfix post-1016 post type-post status-publish format-standard has-post-thumbnail hentry category-template-2 category-uncategorized tag-codex tag-edge-case tag-featured-image tag-image tag-template">
    
    
      <header class="article-header">
        
  
    <h1 class="thumb" class="article-title" itemprop="name">
      web推荐系统知识介绍
    </h1>
  

      </header>
    
    <div class="article-meta">
      
	<a href="/2017/05/10/web推荐系统知识介绍/" class="article-date">
	  <time datetime="2017-05-09T16:00:00.000Z" itemprop="datePublished">五月 10, 2017</time>
	</a>

      
	<span class="ico-folder"></span>
    <a class="article-category-link" href="/categories/统计分析/">统计分析</a>
 
      
    </div>
    <div class="article-entry" itemprop="articleBody">
      
        <p>利用数据提供某种建议是很常见的需求，它可以改善用户体验，好的推荐系统可以比较精准地为用户提供信息，增加购买率。</p>
<a id="more"></a>
<p>目前常见的推荐算法有以下三种：</p>
<pre><code>1. 基于热度进行推荐
2. 基于用户的协同过滤方法
3. 基于物品的协同过滤方法
</code></pre><h3 id="1-基于热度进行推荐"><a href="#1-基于热度进行推荐" class="headerlink" title="1. 基于热度进行推荐"></a>1. 基于热度进行推荐</h3><p>优点是简单粗暴，利用目前访问量最大的一些数据做推荐，技术上可以结合redis一类的内存型NoSQL系统。但缺点也很明显，不够个性化，我们不清楚每个用户的兴趣和习惯，精准率也低。不过在面对一些新用户的时候，由于我们对他们一无所知，所以基于热度进行推荐可能是对于这种情况比较好的一种推荐方法。</p>
<h3 id="2-基于用户的协同过滤方法"><a href="#2-基于用户的协同过滤方法" class="headerlink" title="2. 基于用户的协同过滤方法"></a>2. 基于用户的协同过滤方法</h3><p>这种方法一般会利用用户兴趣爱好，找到有类似兴趣爱好的人，然后根据这些人的爱好向你推荐你可能感兴趣的东西。</p>
<p>为此我们需要找到一种度量两个用户之间相似程度的方法，这可以用“余弦相似度”，从数学的角度理解就是两个向量夹角的余弦值(初中知识)</p>
<p><img src="/assets/images/post_imgs/recommend_system_1.png" alt="两个向量的夹角的余弦值"></p>
<p>计算公式如下：</p>
<p><img src="/assets/images/post_imgs/recommend_system_2.png" alt="公式1-两个向量夹角余弦值计算"></p>
<p>于是可知，cosθ ∈ [-1, 1]</p>
<p>直观上来说，它用来测量两个向量之间的“角度”，如果两个向量指向同一方向，那么余弦值相似度就是1，如果相反，则是-1，如果两个向量互相垂直，为0，这表示两个向量之间没有任何关系。我们可以把这部分概念应用到实际中，但是我们只考虑相关和不想关，即只取0和1两种值。0表示不相关，1表示相关，负相关我们暂时不去考虑，因为这比判定正相关要复杂很多，例如我们可以很明显地看出手办爱好者和动漫迷的关系是正相关(有可能他们都被打了动漫的标签)，但是就很难去判断厨师和程序猿的关系，所以这种关系不明确的情况，一般就赋予0值。</p>
<p>刚才只考虑了两个向量的情况，现在来考虑更普遍的情形。我们先根据两个用户的爱好来计算他们之间的相似度，的在此之前需要知道<a href="http://baike.baidu.com/link?url=QXwmKu75g9jG1MVjtOBsjKyqf9qkDKLJq3arXQJuOPr_rcceVMJbYAky2utAwGFc0n-3tGU430hfeQ_OmxDBXK" target="_blank" rel="noopener">Jaccard公式</a>：</p>
<p><img src="http://images.cnitblog.com/blog2015/70278/201504/292243027244041.png" alt="公式2-Jaccard公式"></p>
<p>N(u)表示用户u的爱好集合，N(v)表示用户v的爱好集合，Jaccard公式可以计算用户u和v的相似度。</p>
<p>还有一个公式计算<a href="http://baike.baidu.com/link?url=r4D7a-iW8dXw6jEP-pftHuvhEhTVAS6DpGgnjXjKHgrYMuZ9kCog22E8wYsL73t7ANH4lzyd2ZEnOOc7keUEsPgHJSI_9KIQSmAgqgBQnRN2X-ybsFckPE62h1m7Whz1" target="_blank" rel="noopener">余弦相似度</a>：</p>
<p><img src="/assets/images/post_imgs/recommend_system_3.png" alt="公式3-余弦相似度公式"></p>
<p>|N(u)|和|N(v)|分表表示用户u和用户v爱好集合的大小。</p>
<h4 id="1-推荐相似用户"><a href="#1-推荐相似用户" class="headerlink" title="(1)推荐相似用户"></a>(1)推荐相似用户</h4><p>有了上面这两个公式，就可以着手计算出每两个用户之间的相似度了。</p>
<p>为此可以建立一个用户-爱好表，比如有A、B、C、D四个用户，以及a、b、c、d、e 5个爱好，这四个用户具有的爱好情况如下：</p>
<pre><code>A | a b d
B | a c
C | b e
D | c d e
</code></pre><p>据此可以建立物品-用户倒排表了：</p>
<pre><code>a | A B
b | A C
c | B D
d | A D
e | C D
</code></pre><p>然后建立一个用户-用户矩阵，矩阵的行和列都是用户，i行j列的数字表示这个元素对应行的用户和对应列的用户的喜欢相同物品的个数，需要注意的是，用户自身不和自己进行比较：</p>
<pre><code>#   A   B   C   D

A   0   1   1   1

B   1   0   0   1

C   1   0   0   1

D   1   1   1   0
</code></pre><p><img src="/assets/images/post_imgs/recommend_system_4.png" alt="用户-用户矩阵"></p>
<p>我们使用余弦相似度的公式来计算：</p>
<p><img src="/assets/images/post_imgs/recommend_system_5.png" alt="计算结果"></p>
<p>根据这个相似度矩阵，就可以很直观地看出任意两个用户之间的相似度了。比如对于用户A来说，他与B、C、D三个用户的相似分别是</p>
<pre><code>A&lt;-&gt;B 0.4082482904638631

A&lt;-&gt;C 0.4082482904638631

A&lt;-&gt;D 0.3333333333333333
</code></pre><p>由此可见A和B、C两个用户比较相似度较高，和D用户相似度较低。</p>
<h4 id="2-推荐物品"><a href="#2-推荐物品" class="headerlink" title="(2)推荐物品"></a>(2)推荐物品</h4><p>对于物品，我们也可以利用相似性来推荐，刚才我们计算出了每两个用户之间的相似性，每个结果都是一个数值，这个数值的取值范围是[0, 1]。于是我们可以大胆地猜测，相似的人可能会喜欢相似的物品，虽然这不一定完全正确，但总能为我们提供一些有用的信息。</p>
<p>给定一个用户u，首先要从除了u的所有用户中选出K个和他最相似的用户，用集合S(u, K)表示。然后将S中用户喜欢的物品全部提取出来，并除去u喜欢的物品，得到一个物品列表，对于每个候选物品i，可以用如下公式计算用户u对它感兴趣的程度：</p>
<p><img src="/assets/images/post_imgs/recommend_system_6.png" alt="计算用户对物品感兴趣的程度"></p>
<p>w(uv)表示用户u和用户v的相似度，r(vi)表示用户v对物品i的喜爱程度。</p>
<p>这里给定一个用户A，相似用户是B、C、D，候选物品为c、e，并取r(vi)都为1，那么根据上面的公式：</p>
<p><img src="/assets/images/post_imgs/recommend_system_7.png" alt="用户A对物品c的喜爱程度"></p>
<p><img src="/assets/images/post_imgs/recommend_system_8.png" alt="用户A对物品e的喜爱程度"></p>
<p>据此可以给出一个量化标准说明某用户对某物品的可能感兴趣程度。</p>
<h4 id="3-基于用户的协同过滤算法的一些问题"><a href="#3-基于用户的协同过滤算法的一些问题" class="headerlink" title="(3)基于用户的协同过滤算法的一些问题"></a>(3)基于用户的协同过滤算法的一些问题</h4><p>在二维向量的情况下，余弦相似度公式等价于：</p>
<p><img src="/assets/images/post_imgs/recommend_system_9.png" alt="二维向量情况下的余弦相似度公式"></p>
<p>如果推广到更一般的形式：</p>
<p><img src="/assets/images/post_imgs/recommend_system_10.png" alt="n维向量情况下的余弦相似度公式"></p>
<p>这里就有一个问题，在高维向量空间中，绝大多数向量之间都离得非常远，因此让他们之间的方向也悬殊很大，也就是说，当兴趣的个数增大时，即使是与给定用户“最相似的用户”，实际上很可能也没有什么相似之处。因此当兴趣数量很多的时候，基于用户的协同过滤方法不是很实用。</p>
<h3 id="3-基于物品的协同过滤方法"><a href="#3-基于物品的协同过滤方法" class="headerlink" title="3. 基于物品的协同过滤方法"></a>3. 基于物品的协同过滤方法</h3><p>这种方法是先计算两个物品之间的相似度，然后将与用户当前物品相似的物品放到一起，并从中为用户推荐可能感兴趣的东西。</p>
<p>假设有ABCD四个用户和abcde五个物品，他们的关系如下(用户喜欢物品)：</p>
<pre><code>A | a b d
B | a c
C | b e
D | c d e
</code></pre><p>用户-物品矩阵</p>
<p>行-用户<br>列-物品</p>
<pre><code>#  a  b  c  d  e

A  1  1  0  1  0

B  1  0  1  0  0

C  0  1  0  0  1

D  0  0  1  1  1
</code></pre><p>物品-用户矩阵(是用户-物品矩阵的转置)</p>
<p>行-物品<br>列-用户</p>
<pre><code>#   A   B   C   D

a   1   1   0   0

b   1   0   1   0

c   0   1   0   1

d   1   0   0   1

e   0   0   1   1
</code></pre><p>如果两个用户的兴趣矩阵完全重合，那么他们的相似度为1，如果完全不重合，相似度为0。</p>
<p>接下来需要计算物品之间的相似度，我们根据余弦相似度公式可以考察两两物品间的相似度(注意物品对自己的相似度要置为0)：</p>
<pre><code>#   a    b    c    d    e

a   0   1/2  1/2  1/2   0

b  1/2   0    0   1/2  1/2

c  1/2   0    0   1/2  1/2

d  1/2  1/2  1/2   0   1/2

e   0   1/2  1/2  1/2   0
</code></pre><p>这个矩阵就是物品相似度矩阵。</p>
<h3 id="一个实例"><a href="#一个实例" class="headerlink" title="一个实例"></a>一个实例</h3><p>这个实例会考察：</p>
<pre><code>1.使用基于用户的协同过滤算法来给指定用户推荐兴趣
2.使用基于物品的协同过滤算法来给指定用户推荐兴趣
</code></pre><p>我们有一个用户兴趣列表users_interests，users_interests中的每一个元素都代表某个用户的兴趣列表。</p>
<pre><code>users_interests = [
    [&quot;Hadoop&quot;, &quot;Big Data&quot;, &quot;HBase&quot;, &quot;Java&quot;, &quot;Spark&quot;, &quot;Storm&quot;, &quot;Cassandra&quot;],
    [&quot;NoSQL&quot;, &quot;MongoDB&quot;, &quot;Cassandra&quot;, &quot;HBase&quot;, &quot;Postgres&quot;],
    [&quot;Python&quot;, &quot;scikit-learn&quot;, &quot;scipy&quot;, &quot;numpy&quot;, &quot;statsmodels&quot;, &quot;pandas&quot;],
    [&quot;R&quot;, &quot;Python&quot;, &quot;statistics&quot;, &quot;regression&quot;, &quot;probability&quot;],
    [&quot;machine learning&quot;, &quot;regression&quot;, &quot;decision trees&quot;, &quot;libsvm&quot;],
    [&quot;Python&quot;, &quot;R&quot;, &quot;Java&quot;, &quot;C++&quot;, &quot;Haskell&quot;, &quot;programming languages&quot;],
    [&quot;statistics&quot;, &quot;probability&quot;, &quot;mathematics&quot;, &quot;theory&quot;],
    [&quot;machine learning&quot;, &quot;scikit-learn&quot;, &quot;Mahout&quot;, &quot;neural networks&quot;],
    [&quot;neural networks&quot;, &quot;deep learning&quot;, &quot;Big Data&quot;, &quot;artificial intelligence&quot;],
    [&quot;Hadoop&quot;, &quot;Java&quot;, &quot;MapReduce&quot;, &quot;Big Data&quot;],
    [&quot;statistics&quot;, &quot;R&quot;, &quot;statsmodels&quot;],
    [&quot;C++&quot;, &quot;deep learning&quot;, &quot;artificial intelligence&quot;, &quot;probability&quot;],
    [&quot;pandas&quot;, &quot;R&quot;, &quot;Python&quot;],
    [&quot;databases&quot;, &quot;HBase&quot;, &quot;Postgres&quot;, &quot;MySQL&quot;, &quot;MongoDB&quot;],
    [&quot;libsvm&quot;, &quot;regression&quot;, &quot;support vector machines&quot;]
]
</code></pre><h4 id="使用基于用户的协同过滤算法来给指定用户推荐兴趣"><a href="#使用基于用户的协同过滤算法来给指定用户推荐兴趣" class="headerlink" title="使用基于用户的协同过滤算法来给指定用户推荐兴趣"></a>使用基于用户的协同过滤算法来给指定用户推荐兴趣</h4><p>1.余弦相似度函数：</p>
<pre><code>def cosine_similarity(v, w):
    return dot(v, w) / math.sqrt(dot(v, v) * dot(w, w))
</code></pre><p>2.对兴趣排重，获得兴趣列表：</p>
<pre><code>unique_interests = sorted(list({ interest
                             for user_interests in users_interests
                             for interest in user_interests }))
</code></pre><p>这会生成一个唯一兴趣列表：</p>
<pre><code>[
    &apos;Big Data&apos;,
    &apos;C++&apos;,
    &apos;Cassandra&apos;,
    &apos;HBase&apos;,
    &apos;Hadoop&apos;,
    &apos;Haskell&apos;,
    &apos;Java&apos;,
    &apos;Mahout&apos;,
    &apos;MapReduce&apos;,
    &apos;MongoDB&apos;,
    &apos;MySQL&apos;,
    &apos;NoSQL&apos;,
    &apos;Postgres&apos;,
    &apos;Python&apos;,
    &apos;R&apos;,
    &apos;Spark&apos;,
    &apos;Storm&apos;,
    &apos;artificial intelligence&apos;,
    &apos;databases&apos;,
    &apos;decision trees&apos;,
    &apos;deep learning&apos;,
    &apos;libsvm&apos;,
    &apos;machine learning&apos;,
    &apos;mathematics&apos;,
    &apos;neural networks&apos;,
    &apos;numpy&apos;,
    &apos;pandas&apos;,
    &apos;probability&apos;,
    &apos;programming languages&apos;,
    &apos;regression&apos;,
    &apos;scikit-learn&apos;,
    &apos;scipy&apos;,
    &apos;statistics&apos;,
    &apos;statsmodels&apos;,
    &apos;support vector machines&apos;,
    &apos;theory&apos;
]
</code></pre><p>3.创建用户-兴趣向量,向量长度是unique_interests的长度：</p>
<pre><code>def make_user_interest_vector(user_interests):
    return [1 if interest in user_interests else 0 for interest in unique_interests]
</code></pre><p>4.生成用户-兴趣矩阵：</p>
<pre><code>user_interest_matrix = map(make_user_interest_vector, users_interests)
</code></pre><p>得到：</p>
<pre><code>[
    [1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
    [0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1],
    [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0],
    [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0]
]
</code></pre><p>5.生成兴趣相似性矩阵：</p>
<pre><code>user_similarities = [[cosine_similarity(interest_vector_i, interest_vector_j)
                            for interest_vector_j in user_interest_matrix]
                                for interest_vector_i in user_interest_matrix]
</code></pre><p>得到：</p>
<pre><code>[[1.0, 0.3380617018914066, 0.0, 0.0, 0.0, 0.1543033499620919, 0.0, 0.0, 0.1889822365046136, 0.5669467095138409, 0.0, 0.0, 0.0, 0.1690308509457033, 0.0], [0.3380617018914066, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0], [0.0, 0.0, 1.0, 0.18257418583505536, 0.0, 0.16666666666666666, 0.0, 0.20412414523193154, 0.0, 0.0, 0.23570226039551587, 0.0, 0.47140452079103173, 0.0, 0.0], [0.0, 0.0, 0.18257418583505536, 1.0, 0.22360679774997896, 0.3651483716701107, 0.4472135954999579, 0.0, 0.0, 0.0, 0.5163977794943222, 0.22360679774997896, 0.5163977794943222, 0.0, 0.2581988897471611], [0.0, 0.0, 0.0, 0.22360679774997896, 1.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5773502691896258], [0.1543033499620919, 0.0, 0.16666666666666666, 0.3651483716701107, 0.0, 1.0, 0.0, 0.0, 0.0, 0.20412414523193154, 0.23570226039551587, 0.20412414523193154, 0.47140452079103173, 0.0, 0.0], [0.0, 0.0, 0.0, 0.4472135954999579, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.2886751345948129, 0.25, 0.0, 0.0, 0.0], [0.0, 0.0, 0.20412414523193154, 0.0, 0.25, 0.0, 0.0, 1.0, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1889822365046136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 1.0, 0.25, 0.0, 0.5, 0.0, 0.0, 0.0], [0.5669467095138409, 0.0, 0.0, 0.0, 0.0, 0.20412414523193154, 0.0, 0.0, 0.25, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.23570226039551587, 0.5163977794943222, 0.0, 0.23570226039551587, 0.2886751345948129, 0.0, 0.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0], [0.0, 0.0, 0.0, 0.22360679774997896, 0.0, 0.20412414523193154, 0.25, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.47140452079103173, 0.5163977794943222, 0.0, 0.47140452079103173, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0], [0.1690308509457033, 0.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.2581988897471611, 0.5773502691896258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]]
</code></pre><p>6.获取和某个用户最相似的用户：</p>
<pre><code>def most_similar_users_to(user_id):
    pairs = [(other_user_id, similarity)                  # find other
         for other_user_id, similarity in                 # users with
            enumerate(user_similarities[user_id])         # nonzero
         if user_id != other_user_id and similarity &gt; 0]  # similarity
    return sorted(pairs,                                   # sort them
              key=lambda (_, similarity): similarity,     # most similar
              reverse=True)                               # first
</code></pre><p>考察和第0个用户相似的用户：</p>
<pre><code>print &quot;User based similarity&quot;
print &quot;most similar to 0&quot;
print most_similar_users_to(0)
</code></pre><p>得到：</p>
<pre><code>User based similarity
most similar to 0
[
    (9, 0.5669467095138409),
    (1, 0.3380617018914066),
    (8, 0.1889822365046136),
    (13, 0.1690308509457033),
    (5, 0.1543033499620919)
]
</code></pre><p>7.使用基于用户的协同算法为某个用户推荐兴趣：</p>
<pre><code>def user_based_suggestions(user_id, include_current_interests=False):
    # sum up the similarities
    suggestions = defaultdict(float)
    for other_user_id, similarity in most_similar_users_to(user_id):
        for interest in users_interests[other_user_id]:
          suggestions[interest] += similarity

    # convert them to a sorted list
    suggestions = sorted(suggestions.items(),
                     key=lambda (_, weight): weight,
                     reverse=True)

    # and (maybe) exclude already-interests
    if include_current_interests:
        return suggestions
    else:
        return [(suggestion, weight)
            for suggestion, weight in suggestions
            if suggestion not in users_interests[user_id]]
</code></pre><p>为第0位用户推荐兴趣：</p>
<pre><code>print &quot;Suggestions for 0&quot;
print user_based_suggestions(0)
</code></pre><p>得到：</p>
<pre><code>[
    (&apos;MapReduce&apos;, 0.5669467095138409),
    (&apos;MongoDB&apos;, 0.50709255283711),
    (&apos;Postgres&apos;, 0.50709255283711),
    (&apos;NoSQL&apos;, 0.3380617018914066),
    (&apos;neural networks&apos;, 0.1889822365046136),
    (&apos;deep learning&apos;, 0.1889822365046136),
    (&apos;artificial intelligence&apos;, 0.1889822365046136),
    (&apos;databases&apos;, 0.1690308509457033),
    (&apos;MySQL&apos;, 0.1690308509457033),
    (&apos;programming languages&apos;, 0.1543033499620919),
    (&apos;Python&apos;, 0.1543033499620919),
    (&apos;Haskell&apos;, 0.1543033499620919),
    (&apos;C++&apos;, 0.1543033499620919),
    (&apos;R&apos;, 0.1543033499620919)
]
</code></pre><p>第0位用户的兴趣如下：</p>
<pre><code>[&quot;Hadoop&quot;, &quot;Big Data&quot;, &quot;HBase&quot;, &quot;Java&quot;, &quot;Spark&quot;, &quot;Storm&quot;, &quot;Cassandra&quot;]
</code></pre><p>发现他对大数据和数据库系统比较感兴趣，再看推荐兴趣的前三名：</p>
<pre><code>(&apos;MapReduce&apos;, 0.5669467095138409)
(&apos;MongoDB&apos;, 0.50709255283711)
(&apos;Postgres&apos;, 0.50709255283711)
</code></pre><p>直观上还是比较合适的一个推荐。</p>
<h4 id="使用基于物品的协同过滤算法来给指定用户推荐兴趣"><a href="#使用基于物品的协同过滤算法来给指定用户推荐兴趣" class="headerlink" title="使用基于物品的协同过滤算法来给指定用户推荐兴趣"></a>使用基于物品的协同过滤算法来给指定用户推荐兴趣</h4><p>1.生成兴趣-用户矩阵：</p>
<pre><code>interest_user_matrix = [[user_interest_vector[j]
                     for user_interest_vector in user_interest_matrix]
                    for j, _ in enumerate(unique_interests)]
</code></pre><p>得到：</p>
<pre><code>[
    [1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0],
    [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
    [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
    [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
    [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
    [0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0],
    [0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0],
    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
    [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0],
    [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
    [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],
    [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
    [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0],
    [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
    [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
    [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0],
    [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],
    [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]
]
</code></pre><p>2.获得和某个兴趣最相似的几个兴趣：</p>
<pre><code>interest_similarities = [[cosine_similarity(user_vector_i, user_vector_j)
                      for user_vector_j in interest_user_matrix]
                     for user_vector_i in interest_user_matrix]
</code></pre><p>得到(数据很多，仅仅是列出来，不用去细看了)：</p>
<pre><code>[[1.0, 0.0, 0.4082482904638631, 0.3333333333333333, 0.8164965809277261, 0.0, 0.6666666666666666, 0.0, 0.5773502691896258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5773502691896258, 0.5773502691896258, 0.4082482904638631, 0.0, 0.0, 0.4082482904638631, 0.0, 0.0, 0.0, 0.4082482904638631, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.7071067811865475, 0.4082482904638631, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35355339059327373, 0.35355339059327373, 0.0, 0.0, 0.5, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4082482904638631, 0.7071067811865475, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4082482904638631, 0.0, 1.0, 0.8164965809277261, 0.5, 0.0, 0.4082482904638631, 0.0, 0.0, 0.5, 0.0, 0.7071067811865475, 0.5, 0.0, 0.0, 0.7071067811865475, 0.7071067811865475, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3333333333333333, 0.0, 0.8164965809277261, 1.0, 0.4082482904638631, 0.0, 0.3333333333333333, 0.0, 0.0, 0.8164965809277261, 0.5773502691896258, 0.5773502691896258, 0.8164965809277261, 0.0, 0.0, 0.5773502691896258, 0.5773502691896258, 0.0, 0.5773502691896258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8164965809277261, 0.0, 0.5, 0.4082482904638631, 1.0, 0.0, 0.8164965809277261, 0.0, 0.7071067811865475, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7071067811865475, 0.7071067811865475, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.7071067811865475, 0.0, 0.0, 0.0, 1.0, 0.5773502691896258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6666666666666666, 0.4082482904638631, 0.4082482904638631, 0.3333333333333333, 0.8164965809277261, 0.5773502691896258, 1.0, 0.0, 0.5773502691896258, 0.0, 0.0, 0.0, 0.0, 0.2886751345948129, 0.2886751345948129, 0.5773502691896258, 0.5773502691896258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5773502691896258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7071067811865475, 0.0, 0.7071067811865475, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7071067811865475, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5773502691896258, 0.0, 0.0, 0.0, 0.7071067811865475, 0.0, 0.5773502691896258, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.5, 0.8164965809277261, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.7071067811865475, 0.7071067811865475, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7071067811865475, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.5773502691896258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7071067811865475, 1.0, 0.0, 0.7071067811865475, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.7071067811865475, 0.5773502691896258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7071067811865475, 0.0, 1.0, 0.7071067811865475, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.5, 0.8164965809277261, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.7071067811865475, 0.7071067811865475, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7071067811865475, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.35355339059327373, 0.0, 0.0, 0.0, 0.5, 0.2886751345948129, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.75, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.7071067811865475, 0.2886751345948129, 0.5, 0.2886751345948129, 0.35355339059327373, 0.5, 0.2886751345948129, 0.35355339059327373, 0.0, 0.0], [0.0, 0.35355339059327373, 0.0, 0.0, 0.0, 0.5, 0.2886751345948129, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.75, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35355339059327373, 0.2886751345948129, 0.5, 0.2886751345948129, 0.0, 0.0, 0.5773502691896258, 0.35355339059327373, 0.0, 0.0], [0.5773502691896258, 0.0, 0.7071067811865475, 0.5773502691896258, 0.7071067811865475, 0.0, 0.5773502691896258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5773502691896258, 0.0, 0.7071067811865475, 0.5773502691896258, 0.7071067811865475, 0.0, 0.5773502691896258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4082482904638631, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.4082482904638631, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.5773502691896258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7071067811865475, 1.0, 0.0, 0.7071067811865475, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.7071067811865475, 0.7071067811865475, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5773502691896258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4082482904638631, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.4082482904638631, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7071067811865475, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8164965809277261, 0.0, 0.0, 0.0, 0.0, 0.7071067811865475, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7071067811865475, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7071067811865475, 0.0, 0.5, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.4082482904638631, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5773502691896258, 0.0, 0.0, 0.0, 0.0, 0.5773502691896258, 0.0, 0.0, 1.0], [0.4082482904638631, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7071067811865475, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.5, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.7071067811865475, 0.0, 0.0, 0.0, 0.7071067811865475, 1.0, 0.0, 0.7071067811865475, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7071067811865475, 0.35355339059327373, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7071067811865475, 1.0, 0.0, 0.0, 0.0, 0.5, 0.7071067811865475, 0.0, 0.5, 0.0, 0.0], [0.0, 0.4082482904638631, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2886751345948129, 0.2886751345948129, 0.0, 0.0, 0.4082482904638631, 0.0, 0.0, 0.4082482904638631, 0.0, 0.0, 0.5773502691896258, 0.0, 0.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.5773502691896258], [0.0, 0.7071067811865475, 0.0, 0.0, 0.0, 1.0, 0.5773502691896258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2886751345948129, 0.2886751345948129, 0.0, 0.0, 0.0, 0.0, 0.5773502691896258, 0.0, 0.8164965809277261, 0.4082482904638631, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.5773502691896258, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7071067811865475, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35355339059327373, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.5, 0.7071067811865475, 0.5, 0.0, 0.0, 0.0, 1.0, 0.7071067811865475, 0.0, 0.5, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.7071067811865475, 0.0, 0.0, 0.0, 0.7071067811865475, 1.0, 0.0, 0.7071067811865475, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2886751345948129, 0.5773502691896258, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5773502691896258, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.4082482904638631, 0.0, 0.5773502691896258], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35355339059327373, 0.35355339059327373, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7071067811865475, 0.5, 0.0, 0.0, 0.0, 0.5, 0.7071067811865475, 0.4082482904638631, 1.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7071067811865475, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5773502691896258, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5773502691896258, 0.0, 0.0, 0.0, 0.0, 0.5773502691896258, 0.0, 0.0, 1.0]]
</code></pre><p>3.获得和某个兴趣最相似的几个兴趣:</p>
<pre><code>def most_similar_interests_to(interest_id):
    similarities = interest_similarities[interest_id]
    pairs = [(unique_interests[other_interest_id], similarity)
         for other_interest_id, similarity in enumerate(similarities)
         if interest_id != other_interest_id and similarity &gt; 0]
    return sorted(pairs,
              key=lambda (_, similarity): similarity,
              reverse=True)
</code></pre><p>我们考察和unique_interests[0]最相似的几个兴趣：</p>
<pre><code>print &quot;Item based similarity&quot;
print &quot;most similar to&quot;, unique_interests[0]
print most_similar_interests_to(0)
</code></pre><p>得到：</p>
<pre><code>Item based similarity
most similar to Big Data
[
    (&apos;Hadoop&apos;, 0.8164965809277261),
    (&apos;Java&apos;, 0.6666666666666666),
    (&apos;MapReduce&apos;, 0.5773502691896258),
    (&apos;Spark&apos;, 0.5773502691896258),
    (&apos;Storm&apos;, 0.5773502691896258),
    (&apos;Cassandra&apos;, 0.4082482904638631),
    (&apos;artificial intelligence&apos;, 0.4082482904638631),
    (&apos;deep learning&apos;, 0.4082482904638631),
    (&apos;neural networks&apos;, 0.4082482904638631),
    (&apos;HBase&apos;, 0.3333333333333333)
]
</code></pre><p>发现和“Big Data”最相似的前三个兴趣分别是：</p>
<pre><code>Hadoop
Java
MapReduce
</code></pre><p>相关性还是比较强的。</p>
<p>4.使用基于物品的协同算法为用户推荐兴趣：</p>
<pre><code>def item_based_suggestions(user_id, include_current_interests=False):
    suggestions = defaultdict(float)
    user_interest_vector = user_interest_matrix[user_id]
    for interest_id, is_interested in enumerate(user_interest_vector):
        if is_interested == 1:
            similar_interests = most_similar_interests_to(interest_id)
            for interest, similarity in similar_interests:
                 suggestions[interest] += similarity

    suggestions = sorted(suggestions.items(),
                     key=lambda (_, similarity): similarity,
                     reverse=True)

    if include_current_interests:
        return suggestions
    else:
        return [(suggestion, weight)
                    for suggestion, weight in suggestions
                        if suggestion not in users_interests[user_id]]
</code></pre><p>我们为第0位用户推荐兴趣：</p>
<pre><code>print &quot;suggestions for user 0&quot;
print item_based_suggestions(0)
</code></pre><p>得到：</p>
<pre><code>suggestions for user 0
[
    (&apos;MapReduce&apos;, 1.861807319565799),
    (&apos;Postgres&apos;, 1.3164965809277263),
    (&apos;MongoDB&apos;, 1.3164965809277263),     
    (&apos;NoSQL&apos;, 1.2844570503761732),
    (&apos;programming languages&apos;, 0.5773502691896258),
    (&apos;MySQL&apos;, 0.5773502691896258),         
    (&apos;Haskell&apos;, 0.5773502691896258),
    (&apos;databases&apos;, 0.5773502691896258),
    (&apos;neural networks&apos;, 0.4082482904638631),
    (&apos;deep learning&apos;, 0.4082482904638631),
    (&apos;C++&apos;, 0.4082482904638631),
    (&apos;artificial intelligence&apos;, 0.4082482904638631),
    (&apos;Python&apos;, 0.2886751345948129),
    (&apos;R&apos;, 0.2886751345948129)
]
</code></pre><p>这个推荐也是合理的。</p>
<h3 id="基于用户还是基于物品？"><a href="#基于用户还是基于物品？" class="headerlink" title="基于用户还是基于物品？"></a>基于用户还是基于物品？</h3><p>在针对大数据集生成推荐列表时，基于物品的过滤要比基于用户的过滤更快，效果也更好，但是基于物品的过滤算法更复杂一点，而且要维护一个物品相似度表，不过好在物品之间的相似度基本不怎么变化，所以很多电商都采用基于物品的协同过滤算法。</p>
<p>参考资料：</p>
<p>[1] Joel Grus 数据科学入门 [M].人民邮电出版社，2016.<br>[2] Create, Chen. 基于用户的协同过滤推荐算法原理和实现[EB/OL].<a href="http://www.cnblogs.com/technology/p/4467895.html" target="_blank" rel="noopener">http://www.cnblogs.com/technology/p/4467895.html</a>.</p>

        <!-- <h3>看了文章如果觉得喜欢的话可以捐赠哦！支付宝二维码：</h3>
        <img src="/assets/images/post_imgs/code_alipay.png" width=300 height=300> -->
      
    </div>
    <footer class="entry-meta entry-footer">
      
	<span class="ico-folder"></span>
    <a class="article-category-link" href="/categories/统计分析/">统计分析</a>

      
  <span class="ico-tags"></span>
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/统计分析/">统计分析</a></li></ul>

      
        
	<link rel="stylesheet" href="https://unpkg.com/gitalk/dist/gitalk.css">
<script src="https://unpkg.com/gitalk/dist/gitalk.min.js"></script>
<script src="/js/md5.min.js"></script>
<div id="gitalk-container"></div>
<script type="text/javascript">
    var gitalk = new Gitalk({
        clientID: '4010e28e5153ab82b468',
        clientSecret: '217df2318bd891ba87b82dae5d67d7ae77bc1f17',
        id: md5(location.href),
        repo: 'nullcc-blog-comments',
        owner: 'nullcc',
        admin: 'nullcc',
        distractionFreeMode: 'true'
    })
    gitalk.render('gitalk-container')
</script>


      
    </footer>
    <hr class="entry-footer-hr">
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2017/05/10/(译)package.json详解/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">上一篇</strong>
      <div class="article-nav-title">
        
          (译)package.json详解
        
      </div>
    </a>
  
  
    <a href="/2017/05/10/node.js的C++扩展入门/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">下一篇</strong>
      <div class="article-nav-title">node.js的C++扩展入门</div>
    </a>
  
</nav>

  
</article>

<!-- Table of Contents -->

  <aside id="sidebar">
    <div id="toc" class="toc-article">
    <strong class="toc-title">文章目录</strong>
    
      <ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-基于热度进行推荐"><span class="nav-number">1.</span> <span class="nav-text">1. 基于热度进行推荐</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-基于用户的协同过滤方法"><span class="nav-number">2.</span> <span class="nav-text">2. 基于用户的协同过滤方法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-推荐相似用户"><span class="nav-number">2.1.</span> <span class="nav-text">(1)推荐相似用户</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-推荐物品"><span class="nav-number">2.2.</span> <span class="nav-text">(2)推荐物品</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-基于用户的协同过滤算法的一些问题"><span class="nav-number">2.3.</span> <span class="nav-text">(3)基于用户的协同过滤算法的一些问题</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-基于物品的协同过滤方法"><span class="nav-number">3.</span> <span class="nav-text">3. 基于物品的协同过滤方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#一个实例"><span class="nav-number">4.</span> <span class="nav-text">一个实例</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#使用基于用户的协同过滤算法来给指定用户推荐兴趣"><span class="nav-number">4.1.</span> <span class="nav-text">使用基于用户的协同过滤算法来给指定用户推荐兴趣</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#使用基于物品的协同过滤算法来给指定用户推荐兴趣"><span class="nav-number">4.2.</span> <span class="nav-text">使用基于物品的协同过滤算法来给指定用户推荐兴趣</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#基于用户还是基于物品？"><span class="nav-number">5.</span> <span class="nav-text">基于用户还是基于物品？</span></a></li></ol>
    
    </div>
  </aside>

</section>
        
      </div>

    </div>
    <!-- <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/categories" class="mobile-nav-link">Categories</a>
  
    <a href="/tags" class="mobile-nav-link">Tags</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
</nav> -->
    <footer id="footer" class="site-footer">
  

  <div class="clearfix container">
      <div class="site-info">
	      &copy; 2023 张先森的代码小屋 All Rights Reserved.
        
      </div>
      <div class="site-credit">
        Theme by <a href="https://github.com/iTimeTraveler/hexo-theme-hipaper" target="_blank">hipaper</a>
      </div>
  </div>
</footer>


<!-- min height -->

<script>
    var wrapdiv = document.getElementById("wrap");
    var contentdiv = document.getElementById("content");

    wrapdiv.style.minHeight = document.body.offsetHeight - document.getElementById("allheader").offsetHeight - document.getElementById("footer").offsetHeight + "px";
    contentdiv.style.minHeight = document.body.offsetHeight - document.getElementById("allheader").offsetHeight - document.getElementById("footer").offsetHeight + "px";


    <!-- headerblur min height -->
    
    
</script>
    
<div style="display: none;">
  <script src="https://s11.cnzz.com/z_stat.php?id=1260716016&web_id=1260716016" language="JavaScript"></script>
</div>

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>
<script src="/js/bootstrap.js"></script>
<script src="/js/main.js"></script>













  </div>

  <a id="rocket" href="#top" class=""></a>
  <script type="text/javascript" src="/js/totop.js" async=""></script>

  <!-- 百度统计 -->
  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?c3ffa09eef07ac510ef2ab126054b1cd";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
  </script>
    
</body>
</html>
